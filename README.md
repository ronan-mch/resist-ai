# Resist AI - a handbook for concerned citizens

This website is a citizen's guide to opposing generative AI's harmful effects on our society. 

> When we talk about generative AI, we mean LLM based text creation models like ChatGPT and Claude, image creation models like DALL-E, Stable Diffusion, etc and video generators like Runway. We are not talking about traditional ML techniques like logistic regression, decision trees, etc.

## Why resist AI?

Generative AI is a fantastic technology with some valuable use cases, but it is being pushed aggressively by tech companies with no regard for its harmful effects on society. Through boycotting, suing and sabotaging generative AI, we can slow its attack on our society and inspire a more thoughtful conversation about how to use these technologies to benefit rather than harm humanity.

### Energy use

Generative AI requires a huge amount of electricity to train and run models. At a time when the world is facing a massive environmental crisis due to carbon emissions, it is beyond stupid to be powering up more data centres with climate heating electricity generation. But that is exactly what is happening. Unfortunately, this is only expected to get worse as tech companies rush to push AI into every corner of our lives.

- [Elon Muskâ€™s xAI gets permit for methane gas generators](https://www.theguardian.com/us-news/2025/jul/03/elon-musk-xai-pollution-memphis)
- [Meta sponsoring construction of new gas generation in Ohio](https://www.datacenterdynamics.com/en/news/ohio-regulators-approve-construction-of-200mw-gas-power-plant-to-serve-meta-data-center-in-new-albany-ohio/)
- [DOE Releases New Report Evaluating Increase in Electricity Demand from Data Centers](https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers)
### Disinformation, deep fakes
We all rely on the online information commons, but AI is destroying it:
- AI generated deep fake videos are used for [harassment](https://www.esafety.gov.au/newsroom/blogs/deepfake-damage-in-schools-how-ai-generated-abuse-is-disrupting-students-families-and-school-communities), or [political manipulation](https://www.npr.org/2024/12/21/nx-s1-5220301/deepfakes-memes-artificial-intelligence-elections).
- AI generated images [flood social media](https://theconversation.com/what-is-ai-slop-why-you-are-seeing-more-fake-photos-and-videos-in-your-social-media-feeds-255538), drowning out human voices.

### Harming workers

AI systems rely on hidden human labour for content moderation and annotation. Content moderation in particular exacts a large toll on its workers, often leaving them traumatised and without access to sufficient psychological support.
- [The human cost of our AI driven future](https://www.noemamag.com/the-human-cost-of-our-ai-driven-future/)
- [Who trains the data for European artificial intelligence?](https://hal.science/hal-04662589/document)

## How to resist AI?

### For citizens

- Digital rights organisation noyb has launched numerous lawsuits against [AI providers](https://noyb.eu/en/project/artificial-intelligence). You can sign up to support their work.

### For social media users
- Don't boost AI generated content through liking it, sharing it or commenting on it
- Do not allow social media companies to use your content to train their models. This guide shows [how to opt out](https://www.techtarget.com/whatis/feature/How-to-opt-out-of-AI-training-across-social-media-platforms) across multiple different platforms.

- If you can, move away from platforms that push GenAI on their users:
  - WhatsApp can be replaced with [Signal](https://signal.org/) a more ethical and privacy aware alternative.
  - Twitter can be replaced with [BlueSky](https://bsky.app/) or [Mastodon](https://mastodon.social/).


### For online writers

If you write online, AI companies will harvest your writing to build their models. How to resist will depend on what platform you use to publish:
- [Substack](https://support.substack.com/hc/en-us/articles/20382615953556-How-can-I-block-AI-from-using-my-Substack-publication-to-train-their-models)
- [Wordpress](https://wordpress.com/blog/2024/02/27/more-control-over-the-content-you-share/)

### For visual artists
If you're a visual artist who publishes online, you can "poison" your images so that they break the AI models that they are used to train.
The [Nightshade](https://nightshade.cs.uchicago.edu/whatis.html) tool will alter your image in a way that is invisible to you, but will damage any model that uses it.

### For website owners
If you own a website, you can sabotage or block AI crawlers by using CDN (Content Delivery Network) level bot protection:
- Cloudflare allows all users to [trap AI crawlers](https://blog.cloudflare.com/ai-labyrinth/) in an AI generated hall of mirrors.
- Akamai provides a product to [manage bots](https://www.akamai.com/products/bot-manager#accordion-7d993699c3-item-2658329830), including AI bots.
- [Squarespace](https://support.squarespace.com/hc/en-us/articles/360022347072-Request-that-AI-models-exclude-your-site) provide a guide for requesting bots to exclude your website.

More technically confident users can setup self-hosted solutions such as:
- [Anubis](https://anubis.techaro.lol/) - a tool for blocking bots
- [Nepenthes](https://zadzmo.org/code/nepenthes/) - a tool for trapping and poisoning bots
