# Resist AI - a handbook for concerned citizens

This website is a citizen's guide to opposing generative AI's harmful effects on our society.

> When we talk about generative AI (GenAI), we mean LLM based text creation models like ChatGPT and Claude, image creation models like DALL-E, Stable Diffusion, etc and video generators like Runway.

<a name="why">
## Why resist AI?
</a>

Generative AI is an important technology with some valuable use cases, but it is being pushed aggressively by tech companies with no regard for its harmful effects on society. Through boycotting, suing and sabotaging generative AI, we can slow its attack on our society and inspire a more thoughtful conversation about how to use these technologies to benefit rather than harm humanity.

<a name="why-energy">
### Energy use
</a>

Generative AI requires a huge amount of electricity to train and run models. At a time when the world is facing a massive environmental crisis due to carbon emissions, it is beyond stupid to build more fossil fuel powered data centres. But that is exactly what is happening. Unfortunately, this is only expected to get worse as tech companies rush to push AI into every corner of our lives.

- [Elon Muskâ€™s xAI gets permit for methane gas generators](https://www.theguardian.com/us-news/2025/jul/03/elon-musk-xai-pollution-memphis)
- [Meta sponsoring construction of new gas generation in Ohio](https://www.datacenterdynamics.com/en/news/ohio-regulators-approve-construction-of-200mw-gas-power-plant-to-serve-meta-data-center-in-new-albany-ohio/)
- [DOE Releases New Report Evaluating Increase in Electricity Demand from Data Centers](https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers)

<a name="why-disinfo">
### Disinformation, deep fakes
</a>

Disinformation is nothing new, but AI turbocharges it:

- AI generated deep fake videos are used for [harassment](https://www.esafety.gov.au/newsroom/blogs/deepfake-damage-in-schools-how-ai-generated-abuse-is-disrupting-students-families-and-school-communities), or [political manipulation](https://www.npr.org/2024/12/21/nx-s1-5220301/deepfakes-memes-artificial-intelligence-elections).
- AI generated images [flood social media](https://theconversation.com/what-is-ai-slop-why-you-are-seeing-more-fake-photos-and-videos-in-your-social-media-feeds-255538), drowning out human connections.
- AI is being used to [generate bogus research articles](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003152#sec008) hampering the scientific process.
<!-- - AI hallucinations more generally - causing harm etc, look for a source -->

<a name="why-workers">
### Harming workers
</a>

AI systems rely on hidden human labour for content moderation and annotation. Content moderation in particular exacts a large toll on its workers, often leaving them traumatised and without access to sufficient psychological support.

- [OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic](https://time.com/6247678/openai-chatgpt-kenya-workers/)
- [The human cost of our AI driven future](https://www.noemamag.com/the-human-cost-of-our-ai-driven-future/)
- [Who trains the data for European artificial intelligence?](https://hal.science/hal-04662589/document)

<a name="how">
## How to resist AI?
</a>

<a name="how-everyone">
### For everyone
</a>

- Don't believe the hype! AI companies routinely exaggerate the capabilities of their models in order to attract investment and drive growth. LLMs are good at writing text, but that is [not a replacement for human intelligence](https://www.theguardian.com/commentisfree/2025/jun/10/billion-dollar-ai-puzzle-break-down). Moreover, outlandish predictions of future benefits from AI are designed to [mask the real harm](https://www.fastcompany.com/91339834/ai-hype-dark-facts) that AI systems are causing now.
- Oppose data center construction: GenAI companies are building gigantic data centers across the world to power their systems. These consume massive amounts of electricity and water and provide little benefit to the communities affected. In countries such as [Chile](https://www.disconnect.blog/p/how-to-stop-a-data-center) and the [USA](https://www.datacenterwatch.org/report), activists have succeeded in blocking these developments through public information and protest. Support campaigns against data centers in your area.
- Digital rights organisation noyb has launched numerous lawsuits against [AI providers](https://noyb.eu/en/project/artificial-intelligence). You can become a member to support their work.

<a name="how-some">
### For social media users
</a>

- Don't boost AI generated content through liking it, sharing it or commenting on it **need guidance on how to recognise AI content**
- Do not allow social media companies to use your content to train their models. This guide shows [how to opt out](https://www.techtarget.com/whatis/feature/How-to-opt-out-of-AI-training-across-social-media-platforms) across multiple different platforms.

- If you can, move away from platforms that push GenAI on their users:
  - WhatsApp can be replaced with [Signal](https://signal.org/) a more ethical and privacy aware alternative.
  - Twitter can be replaced with [BlueSky](https://bsky.app/) or [Mastodon](https://mastodon.social/).

<a name="how-writers">
### For online writers
</a>

If you write online, AI companies will harvest your writing to build their models. How to resist will depend on what platform you use to publish:

- [Substack](https://support.substack.com/hc/en-us/articles/20382615953556-How-can-I-block-AI-from-using-my-Substack-publication-to-train-their-models)
- [Wordpress](https://wordpress.com/blog/2024/02/27/more-control-over-the-content-you-share/)

<a name="how-artists">
### For visual artists
</a>

If you're a visual artist who publishes online, you can "poison" your images so that they break the AI models that they are used to train.
The [Nightshade](https://nightshade.cs.uchicago.edu/whatis.html) tool will alter your image in a way that is invisible to humans, but will damage any model that uses it.

<a name="how-websites">
### For website owners
</a>

If you own a website, you can sabotage or block AI crawlers by using CDN (Content Delivery Network) level bot protection:

- Cloudflare allows all users to [trap AI crawlers](https://blog.cloudflare.com/ai-labyrinth/) in an AI generated hall of mirrors.
- Akamai provides a product to [manage bots](https://www.akamai.com/products/bot-manager#accordion-7d993699c3-item-2658329830), including AI bots.
- [Squarespace](https://support.squarespace.com/hc/en-us/articles/360022347072-Request-that-AI-models-exclude-your-site) provide a guide for requesting bots to exclude your website.

More technically confident users can setup self-hosted solutions such as:

- [Anubis](https://anubis.techaro.lol/) - a tool for blocking bots
- [Nepenthes](https://zadzmo.org/code/nepenthes/) - a tool for trapping and poisoning bots

<a name="how-educators">
### For educators
</a>

- Read the [open letter](https://openletter.earth/an-open-letter-from-educators-who-refuse-the-call-to-adopt-genai-in-education-cb4aee75) from educators refusing to adopt GenAI and sign and share it if you agree with its contents.
